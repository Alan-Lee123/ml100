# ml100
100 Days of Machine Learning Coding. Try to reimplement common deep learning algorithms in 100 day.

## day1
Implement vgg16 and train it on CIFAR10 dataset. Achieve accuracy on test set: 85.78%

## day2
Implement resnet18 and train it on CIFAR10 dataset. Achieve accuracy on test set: 89.35%

## day3
Implement BatchNormalization. Replace Official BatchNorm in resnet18, Achieve accuracy on CIFAR10 test set: 89.09%

## day4
Implement Adam Algorithm. Test it on CIFAR10 dataset.

## day5
Implement Linear layer. Replace Official Linear layer in resnet18 and test it on CIFAR10.

## day6
Implement Convolution layer. Replace Official Conv2d in resnet18 and test it on CIFAR10. <br> Custom Convolution layer's speed is 41% of Official Conv2d, accuracy on CIFAR10 is about the same

## day7
Implement activation functions. Including ReLU, GeLU, Sigmoid and Sin. <br> Train resne18 10 epoch on CIFAR10, with different activation functions, ReLU, GeLU, Sigmoid and Sin achieves test accuracy: 0.7771, 0.7831, 0.5285, 0.7494